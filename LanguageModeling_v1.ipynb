{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LanguageModeling_v1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "2M7uvE6kdQCa",
        "colab_type": "code",
        "outputId": "7863c1e4-7a3f-415f-97cb-178d46aeaf82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "import keras.utils as ku \n",
        "import numpy as np\n",
        "np.random.seed(1)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "7MB98Fo-dV5m",
        "colab_type": "code",
        "outputId": "9c2ebd53-d21b-4753-aabe-fd01ce96a60f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pzT0Eozldr1H",
        "colab_type": "code",
        "outputId": "d45fbd8d-a93e-473d-89e8-514a401bb0d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "import os\n",
        "print os.getcwd()\n",
        "listdir(\"/content/gdrive/My Drive/Colab Notebooks\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BC_USDT_30min',\n",
              " 'BTC_USD_TPU.ipynb',\n",
              " 'BTC_USD_TPU_v2.ipynb',\n",
              " 'glove.6B.50d.txt',\n",
              " 'text8_processed',\n",
              " 'LanguageModeling_v1.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "8K0g-Qs6d5Zu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qaU8CgYmeMPE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_glove_vecs(glove_file):\n",
        "    with open(glove_file, 'r') as f:\n",
        "        words = set()\n",
        "        word_to_vec_map = {}\n",
        "        for line in f:\n",
        "            line = line.strip().split()\n",
        "            curr_word = line[0]\n",
        "            words.add(curr_word)\n",
        "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
        "        \n",
        "        i = 1\n",
        "        words_to_index = {}\n",
        "        index_to_words = {}\n",
        "        for w in sorted(words):\n",
        "            words_to_index[w] = i\n",
        "            index_to_words[i] = w\n",
        "            i = i + 1\n",
        "    return words_to_index, index_to_words, word_to_vec_map\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vogph341eNj4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs(\"/content/gdrive/My Drive/Colab Notebooks/glove.6B.50d.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ctMUQLEZeecr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter    \n",
        "\n",
        "def preprocess(text):\n",
        "\n",
        "    # Replace punctuation with tokens so we can use them in our model\n",
        "    text = text.lower()\n",
        "    text = text.replace('.', ' . <SPLIT>')\n",
        "    #text = text.replace(',', ' <COMMA> ')\n",
        "    #text = text.replace('\"', ' <QUOTATION_MARK> ')\n",
        "    #text = text.replace(';', ' <SEMICOLON> ')\n",
        "    #text = text.replace('!', ' <EXCLAMATION_MARK> ')\n",
        "    #text = text.replace('?', ' <QUESTION_MARK> ')\n",
        "    #text = text.replace('(', ' <LEFT_PAREN> ')\n",
        "    #text = text.replace(')', ' <RIGHT_PAREN> ')\n",
        "    #text = text.replace('--', ' <HYPHENS> ')\n",
        "    #text = text.replace('?', ' <QUESTION_MARK> ')\n",
        "    # text = text.replace('\\n', ' <NEW_LINE> ')\n",
        "    #text = text.replace(':', ' <COLON> ')\n",
        "    sentences = text.split('<SPLIT>')\n",
        "    \n",
        "    words = [sentence.split() for sentence in sentences]\n",
        "    words2 = text.split()\n",
        "    \n",
        "    # Remove all words with  5 or fewer occurences\n",
        "    word_counts = Counter(words2)\n",
        "    #trimmed_words = [[x for x in y if word_counts[x] > 5] for y in words]\n",
        "    words_not_in_glove = set(word_counts.keys()) - set(word_to_index.keys())\n",
        "    \n",
        "    trimmed_words = [[x for x in y if ((x not in words_not_in_glove) and ( word_counts[x] > 50)) ] for y in words]\n",
        "    return trimmed_words\n",
        "    \n",
        "\n",
        "def get_batches(int_text, batch_size, seq_length):\n",
        "    \"\"\"\n",
        "    Return batches of input and target\n",
        "    :param int_text: Text with the words replaced by their ids\n",
        "    :param batch_size: The size of batch\n",
        "    :param seq_length: The length of sequence\n",
        "    :return: A list where each item is a tuple of (batch of input, batch of target).\n",
        "    \"\"\"\n",
        "    n_batches = int(len(int_text) / (batch_size * seq_length))\n",
        "\n",
        "    # Drop the last few characters to make only full batches\n",
        "    xdata = np.array(int_text[: n_batches * batch_size * seq_length])\n",
        "    ydata = np.array(int_text[1: n_batches * batch_size * seq_length + 1])\n",
        "\n",
        "    x_batches = np.split(xdata.reshape(batch_size, -1), n_batches, 1)\n",
        "    y_batches = np.split(ydata.reshape(batch_size, -1), n_batches, 1)\n",
        "\n",
        "    return list(zip(x_batches, y_batches))\n",
        "\n",
        "\n",
        "def create_lookup_tables(words):\n",
        "    \"\"\"\n",
        "    Create lookup tables for vocabulary\n",
        "    :param words: Input list of words\n",
        "    :return: A tuple of dicts.  The first dict....\n",
        "    \"\"\"\n",
        "    word_counts = Counter(words)\n",
        "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "    int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab)}\n",
        "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
        "\n",
        "    return vocab_to_int, int_to_vocab\n",
        "\n",
        "def tokenize_list(l_words, vocab_to_int):\n",
        "    tokenized_list = [vocab_to_int[word] for word in l_words]\n",
        "    return tokenized_list\n",
        "    \n",
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)]\n",
        "    return Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iGGYEqpae8GT",
        "colab_type": "code",
        "outputId": "8886c7b9-0dc1-43e0-a69b-add4e48a636d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "cell_type": "code",
      "source": [
        "file1 = open(\"/content/gdrive/My Drive/Colab Notebooks/text8_processed\",\"r+\") \n",
        "text =  file1.read() \n",
        "print text[:1000]\n",
        "words = preprocess(text)\n",
        "print words[0:4]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans culottes of the french revolution. whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization of society it has also been taken up as a positive label by self defined anarchists. the word anarchism is derived from the greek without archons ruler chief king . anarchism as a political philosophy is the belief that rulers are unnecessary and should be abolished although there are differing interpretations of what this means. anarchism also refers to related social movements that advocate the elimination of authoritarian institutions particularly the state. the word anarchy as most anarchists use it does not imply chaos nihilism or anomie but rather a harmonious anti authoritarian society. in place of what are regarded as authoritarian political structures and coercive economic in\n",
            "[['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against', 'early', 'working', 'class', 'radicals', 'including', 'the', 'of', 'the', 'english', 'revolution', 'and', 'the', 'of', 'the', 'french', 'revolution', '.'], ['whilst', 'the', 'term', 'is', 'still', 'used', 'in', 'a', 'pejorative', 'way', 'to', 'describe', 'any', 'act', 'that', 'used', 'violent', 'means', 'to', 'destroy', 'the', 'organization', 'of', 'society', 'it', 'has', 'also', 'been', 'taken', 'up', 'as', 'a', 'positive', 'label', 'by', 'self', 'defined', 'anarchists', '.'], ['the', 'word', 'anarchism', 'is', 'derived', 'from', 'the', 'greek', 'without', 'ruler', 'chief', 'king', '.'], ['anarchism', 'as', 'a', 'political', 'philosophy', 'is', 'the', 'belief', 'that', 'rulers', 'are', 'unnecessary', 'and', 'should', 'be', 'abolished', 'although', 'there', 'are', 'differing', 'interpretations', 'of', 'what', 'this', 'means', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eWL1J-zTfb3m",
        "colab_type": "code",
        "outputId": "06328f1f-e568-4542-ff25-ba6c3cab6734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "577782"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "f6EXuR2ufjfd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def training_data(data, length = 5):\n",
        "    input_sequences = []\n",
        "    for line in data:\n",
        "        for i in range(1, len(line)):\n",
        "            l = random.randint(1,length)\n",
        "            n_gram_sequence = line[max(0, (i-l)):i+1]\n",
        "            input_sequences.append(n_gram_sequence)\n",
        "    return input_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4u3QFrzrfkBc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = training_data(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4xGVfZn_vH2M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train_data = train_data[:10000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jhoFul_7fl0s",
        "colab_type": "code",
        "outputId": "9563cbd3-4d98-42d3-8d93-78529ea11533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "print len(train_data)\n",
        "print train_data[:10]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11652975\n",
            "[['anarchism', 'originated'], ['anarchism', 'originated', 'as'], ['anarchism', 'originated', 'as', 'a'], ['a', 'term'], ['anarchism', 'originated', 'as', 'a', 'term', 'of'], ['a', 'term', 'of', 'abuse'], ['as', 'a', 'term', 'of', 'abuse', 'first'], ['of', 'abuse', 'first', 'used'], ['first', 'used', 'against'], ['first', 'used', 'against', 'early']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FGUIrtNxfveb",
        "colab_type": "code",
        "outputId": "0422e6ca-8516-40b3-c4fb-7bba82cf10ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "X = [l[:-1] for l in train_data]\n",
        "print \"Done with X\"\n",
        "Y = [l[-1] for l in train_data]\n",
        "starting_word = [l[0] for l in train_data]\n",
        "\n",
        "print len(X)\n",
        "print len(Y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done with X\n",
            "11652975\n",
            "11652975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1vOyHAayfzyp",
        "colab_type": "code",
        "outputId": "228af44a-3879-4a9a-da8d-66b17ce9d49c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print len(set(Y))\n",
        "\n",
        "print len(starting_word)\n",
        "unique_words = set(starting_word + Y)\n",
        "print len(unique_words)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15058\n",
            "11652975\n",
            "15058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-IujGbimf8Ty",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab_to_int, int_to_vocab = create_lookup_tables(list(unique_words))\n",
        "Y_classes = len(int_to_vocab.keys())\n",
        "Y_tokenized = tokenize_list(Y, vocab_to_int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k6Zj9OTOgGnc",
        "colab_type": "code",
        "outputId": "2f79a4d7-a49d-4a90-9ea8-fea8231e9ee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(Y_tokenized)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11652975"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "hAnHt0O_mo-8",
        "colab_type": "code",
        "outputId": "3999e8db-6ace-4b0b-f9c8-1105080a711b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "maxLen = len(max(X, key=len))\n",
        "maxLen"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "0M8KGvf5gJ6U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sentences_to_indices(X, word_to_index, max_len):\n",
        "    \"\"\"\n",
        "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
        "    The output shape should be such that it can be given to `Embedding()` (described in Figure 4). \n",
        "    \n",
        "    Arguments:\n",
        "    X -- array of sentences (strings), of shape (m, 1)\n",
        "    word_to_index -- a dictionary containing the each word mapped to its index\n",
        "    max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this. \n",
        "    \n",
        "    Returns:\n",
        "    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)\n",
        "    \"\"\"\n",
        "    \n",
        "    m = len(X)                                   # number of training examples\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Initialize X_indices as a numpy matrix of zeros and the correct shape (≈ 1 line)\n",
        "    X_indices = np.zeros((m,max_len))\n",
        "    \n",
        "    for i in range(m):                               # loop over training examples\n",
        "        \n",
        "        # Convert the ith training sentence in lower case and split is into words. You should get a list of words.\n",
        "        sentence_words = X[i]\n",
        "        \n",
        "        # Initialize j to 0\n",
        "        j = 0\n",
        "        l_sentence = len(X[i])\n",
        "        # Loop over the words of sentence_words\n",
        "        for w in sentence_words:\n",
        "            # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
        "            X_indices[i, (max_len - l_sentence + j)] = word_to_index[w]\n",
        "            # Increment j to j + 1\n",
        "            j = j + 1\n",
        "            \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return X_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ac1RJd-xibHP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_tokenized_array = np.array(Y_tokenized)\n",
        "X_train_indices = sentences_to_indices(X, vocab_to_int, maxLen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8KA_D9tYgMpr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
        "    \"\"\"\n",
        "    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n",
        "    \n",
        "    Arguments:\n",
        "    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.\n",
        "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
        "    \n",
        "    Returns:\n",
        "    embedding_layer -- pretrained layer Keras instance\n",
        "    \"\"\"\n",
        "    \n",
        "    vocab_len = len(word_to_index) + 1                  # adding 1 to fit Keras embedding (requirement)\n",
        "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      # define dimensionality of your GloVe word vectors (= 50)\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Initialize the embedding matrix as a numpy array of zeros of shape (vocab_len, dimensions of word vectors = emb_dim)\n",
        "    emb_matrix = np.zeros((vocab_len,emb_dim))\n",
        "    \n",
        "    # Set each row \"index\" of the embedding matrix to be the word vector representation of the \"index\"th word of the vocabulary\n",
        "    for word, index in word_to_index.items():\n",
        "        emb_matrix[index, :] = word_to_vec_map[word]\n",
        "        \n",
        "    # Define Keras embedding layer with the correct output/input sizes, make it trainable. Use Embedding(...). Make sure to set trainable=False. \n",
        "    #embedding_layer = tf.keras.layers.Embedding(vocab_len,emb_dim, weights = [emb_matrix], trainable = False)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Build the embedding layer, it is required before setting the weights of the embedding layer. Do not modify the \"None\".\n",
        "    #embedding_layer.build((None,))\n",
        "    \n",
        "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
        "    #embedding_layer.set_weights([emb_matrix])\n",
        "    \n",
        "    return vocab_len, emb_dim, emb_matrix\n",
        "    #return embedding_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gPm6IPBDgSnY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab_len, emb_dim, emb_matrix = pretrained_embedding_layer(word_to_vec_map, vocab_to_int)\n",
        "#el= pretrained_embedding_layer(word_to_vec_map, word_to_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Aen_wYIgVHP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Language_Modeling_v2(input_shape2,word_to_vec_map, word_to_index):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    #model.add(Input(shape = input_shape, dtype='float32'))\n",
        "    #model.add(el)\n",
        "    model.add(tf.keras.layers.Embedding(vocab_len,emb_dim, weights = [emb_matrix], trainable = False,input_shape=input_shape2))\n",
        "    #model.add(tf.keras.layers.Embedding(vocab_len,emb_dim, weights = [emb_matrix], trainable = False,input_shape=input_shape2).build((None,)))\n",
        "    #model.add(tf.keras.layers.Embedding(vocab_len,emb_dim, trainable = False,input_shape=input_shape2).build((None,)).set_weights([emb_matrix]))\n",
        "    \n",
        "    model.add(tf.keras.layers.LSTM(128,return_sequences=True))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.LSTM(128,return_sequences=False))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(Y_classes))\n",
        "    model.add(tf.keras.layers.Activation('softmax'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UdsfaZ7wggA1",
        "colab_type": "code",
        "outputId": "5013409d-30e4-4690-ee3d-6015127a6aa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "maxLen = len(max(X, key=len))\n",
        "maxLen"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "SpsXIpdFgixk",
        "colab_type": "code",
        "outputId": "ffda7005-4654-47e8-de59-0c869be2aa26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "model = Language_Modeling_v2((maxLen,),word_to_vec_map, vocab_to_int )\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 5, 50)             752950    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 5, 128)            91648     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 5, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 15058)             1942482   \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 15058)             0         \n",
            "=================================================================\n",
            "Total params: 2,918,664\n",
            "Trainable params: 2,165,714\n",
            "Non-trainable params: 752,950\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CXdcfFhyglxl",
        "colab_type": "code",
        "outputId": "eff2c3e8-533d-446f-960d-a929fcc09249",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.1.209.162:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 8100473102259489895)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 14916173854151612728)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 17848467561482493875)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 9209190503702516931)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 2160008521271984027)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 2014851620198638289)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 1473852060692049010)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 12298279867424677908)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 16368736187554397842)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 5093311038148908524)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 8400103157977295785)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 9886889165267043477)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bYVZhvedgx83",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tpu_model.compile(\n",
        "    optimizer=tf.train.AdamOptimizer(),\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    metrics=['categorical_accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZmKPkM71g6Ph",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_gen(batch_size):\n",
        "  while True:\n",
        "    offset = np.random.randint(0, X_train_indices.shape[0] - batch_size)\n",
        "    #yield X_train_indices[offset:offset+batch_size], Y_train[offset:offset + batch_size]\n",
        "    yield X_train_indices[offset:offset+batch_size], convert_to_one_hot(Y_tokenized_array[offset:offset + batch_size], C = Y_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kXLuUpGYg7G-",
        "colab_type": "code",
        "outputId": "5a5c777c-c6b6-4d7f-99d6-1978e5a65c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "tpu_model.fit_generator(\n",
        "    train_gen(128),\n",
        "    epochs=1,\n",
        "    steps_per_epoch=10000,\n",
        "    #validation_data=(X_test, Y_test),\n",
        "    #class_weight = {0:1,1:8,2:8,3:40}\n",
        ")\n",
        "\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name=u'core_id0'), TensorSpec(shape=(16, 5), dtype=tf.float32, name=u'embedding_input_10'), TensorSpec(shape=(16, 15058), dtype=tf.float32, name=u'activation_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for embedding_input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 4.54245901108 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "10000/10000 [==============================] - 5243s 524ms/step - loss: 6.8655 - categorical_accuracy: 0.0675\n",
            "5243.60794783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rvxZ7b-oiQDz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#cpu_model = tpu_model.sync_to_cpu()\n",
        "#cpu_model.save('/content/gdrive/My Drive/Colab Notebooks/language_model_v1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qfFPbf6Y4P2G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sAlxH9Hn9ySy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VdqDaR3KW3Ad",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "c082e718-5338-4aed-ee55-0b9940d3ff1e"
      },
      "cell_type": "code",
      "source": [
        "cpu_model = tpu_model.sync_to_cpu()\n",
        "cpu_model.save('/content/gdrive/My Drive/Colab Notebooks/language_model_v2.h5')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FUwJrdxuW5Am",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def string_to_input(string,word_to_index, max_len ):\n",
        "  sentence = string.strip().lower().split()\n",
        "  sentence2 = [word for word in sentence if word in word_to_index.keys()]\n",
        "  if len(sentence2) > 5:\n",
        "    sentence2 = sentence2[-5:]\n",
        "  return sentences_to_indices([sentence2], word_to_index, max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aD-G4Bgu6L5L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = cpu_model.predict(string_to_input(\"This is a bat\", vocab_to_int, 5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yyXsNvrK8VNk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2b29bc4-a84e-4b34-ff18-48b2fc686644"
      },
      "cell_type": "code",
      "source": [
        "np.argmax(pred)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13008"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "MW-xHEgH8oie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe7a76a5-2d34-4978-813e-c68b27aa994c"
      },
      "cell_type": "code",
      "source": [
        "int_to_vocab[np.argmax(pred)]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'of'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "94Y9BY_I8-s5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "string = \"police\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t8x0mqQp8x-f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "77b60f25-8534-4966-e924-d974e5257d42"
      },
      "cell_type": "code",
      "source": [
        "print string_to_input(string, vocab_to_int, 5)\n",
        "int_to_vocab[np.argmax(cpu_model.predict(string_to_input(string, vocab_to_int, 5)))]"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0.    0.    0.    0. 8593.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "metadata": {
        "id": "2viDRmpk9BXr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}